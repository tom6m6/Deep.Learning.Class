{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from cnn_np_version import ImageCNN\n",
    "from cnn_easy_version import ImageCNN as ImageCNN_easy\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset():\n",
    "    def __init__(self, data_path, train=True, transform=None):\n",
    "        X, y = self.load_data(data_path, train)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.y is None:\n",
    "            return img\n",
    "        else:\n",
    "            return img, int(self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def load_data(self, data_path, train):\n",
    "        y_train = None\n",
    "\n",
    "        if train:\n",
    "            with open(data_path + '_labels', 'rb') as f:\n",
    "                y_train = np.asarray(pickle.load(f)).reshape(-1)\n",
    "\n",
    "        with open(data_path + '_images', 'rb') as f:\n",
    "            x_train = np.asarray(pickle.load(f)).reshape(-1, 3, 32*32)\n",
    "        return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def display_cifar():\n",
    "    data_train = CIFAR10Dataset('./input/train', train=True)\n",
    "    fig = plt.figure()\n",
    "    index = np.arange(len(data_train))\n",
    "    np.random.shuffle(index)\n",
    "    index2label = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(np.transpose(data_train[index[i]][0].reshape(3, 32, 32), (1, 2, 0)), interpolation='none')\n",
    "        plt.title(\"Ground Truth: {}\".format(index2label[data_train[index[i]][1]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    train_set = CIFAR10Dataset('./input/train', train=True,\n",
    "                             transform = transforms.Compose([\n",
    "                                         transforms.ToTensor()\n",
    "                                         ]))\n",
    "    test_set = CIFAR10Dataset('./input/test', train=False,\n",
    "                            transform = transforms.Compose([\n",
    "                                        transforms.ToTensor()\n",
    "                                        ]))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def inference_with_CNN_np(train_set, test_set):\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    model = ImageCNN((32, 32) , 10, 3, 16, (5, 5), (2, 2), (3, 3), (2, 2))\n",
    "    checkpoint = torch.load('./cnn_model.pt')\n",
    "    model.load_state_dict_to_np(checkpoint)\n",
    "\n",
    "    X = torch.stack(list(test_set), 0)\n",
    "    X = X.reshape(-1, 3, 32, 32)\n",
    "    y_hat = model.forward_np(X)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    pred_txt = [str(w) for w in y_hat]\n",
    "    g = open('output/predict.txt', 'w')\n",
    "    g.write('\\n'.join(pred_txt))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_CNN_easy(train_set, test_set):\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "    model = ImageCNN_easy(10, 3, 16, (5, 5), (2, 2), (3, 3), (2, 2))\n",
    "\n",
    "    checkpoint = torch.load('./cnn_model.pt')\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "        for i, Xy in enumerate(train_dataloader):\n",
    "            #if i> 10:continue\n",
    "            X, y = Xy\n",
    "            X = X.reshape(-1, 3, 32, 32)\n",
    "            y_hat = model(X).squeeze(1)\n",
    "            loss = loss_func(y_hat, y.long()).sum()\n",
    "\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += loss.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "        print('epoch %d, loss %.4f, train acc %.3f'\n",
    "              % (epoch, train_l_sum / n, train_acc_sum / n))\n",
    "\n",
    "    torch.save(model.state_dict(), './cnn_model.pt')\n",
    "    X = torch.stack(list(test_set), 0)\n",
    "    X = X.reshape(-1, 3, 32, 32)\n",
    "    y_hat = model.forward(X)\n",
    "    y_hat = y_hat[:, :].argmax(dim=1).numpy()\n",
    "    pred_txt = [str(w) for w in y_hat]\n",
    "    g = open('output/predict.txt', 'w')\n",
    "    g.write('\\n'.join(pred_txt))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def zip_fun():\n",
    "    path=os.getcwd()\n",
    "    newpath=path+\"/output/\"\n",
    "    os.chdir(newpath)\n",
    "    os.system('zip prediction.zip predict.txt')\n",
    "    os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, test_set = load_cifar10()\n",
    "\n",
    "    #display_cifar();\n",
    "\n",
    "    inference_with_CNN_np(train_set, test_set)\n",
    "\n",
    "    #train_with_CNN_easy(train_set, test_set)\n",
    "\n",
    "    zip_fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
