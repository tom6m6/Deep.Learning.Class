{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63effdb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "from rnn_with_atten import Sequence_Modeling\n",
    "import os\n",
    "\n",
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afcf1d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_string(string_length):\n",
    "    \"\"\"Generate a random string\"\"\"\n",
    "\n",
    "    letters = string.ascii_uppercase\n",
    "    return ''.join(random.choice(letters) for i in range(string_length))\n",
    "\n",
    "def get_string_batch(batch_size, length):\n",
    "    batched_examples = [generate_random_string(length) for _ in range(batch_size)]\n",
    "    enc_x = [[ord(ch)-ord('A')+1 for ch in list(exp)] for exp in batched_examples]\n",
    "    y = [[o for o in reversed(e_idx)] for e_idx in enc_x]\n",
    "    dec_x = [[0]+e_idx[:-1] for e_idx in y]\n",
    "    return (torch.tensor(enc_x, dtype=torch.int32), \\\n",
    "            torch.tensor(dec_x, dtype=torch.int32), \\\n",
    "            torch.tensor(y, dtype=torch.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21fbb7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_batch(test_set):\n",
    "    enc_x = [[ord(ch)-ord('A')+1 for ch in list(exp)] for exp in test_set]\n",
    "    return torch.tensor(enc_x, dtype=torch.int32).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d66930",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(enc_x, model, state):\n",
    "    output = [0]\n",
    "\n",
    "    enc_hidden, state = model.encode(enc_x, state)\n",
    "    for t in range(len(enc_x[0])):\n",
    "        is_first_step = True if t ==0 else False\n",
    "        enc_y = torch.tensor([output[-1]]).view(1, 1)\n",
    "        Y, state = model.decode(enc_y, enc_hidden, state, is_first_step)\n",
    "        output.append(int(Y.squeeze(1).argmax(dim=1).item()))\n",
    "\n",
    "    output = ''.join([chr(i+64) for i in output[1:]])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36dc2c03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens):\n",
    "    return torch.zeros((1, batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe18adc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    with open(file_path) as f:\n",
    "        test_set = f.readlines()\n",
    "\n",
    "    test_set = [line.strip() for line in test_set]\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148eaa4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_RNN(test_set):\n",
    "    batch_size, num_hiddens = 64, 100\n",
    "\n",
    "    word_num = ord('Z')-ord('A')+2\n",
    "    model = Sequence_Modeling(word_num, 100, word_num, num_hiddens)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 10000\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        state = init_rnn_state(batch_size, num_hiddens)\n",
    "        enc_x, enc_y, y = get_string_batch(batch_size, 8)\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "\n",
    "        # print(X.shape, y.shape, state[0].shape)\n",
    "        enc_hidden, state = model.encode(enc_x, state)\n",
    "        y_hat, _ = model.decode(enc_y, enc_hidden, state)\n",
    "        # print(y_hat.size(), y.size())\n",
    "        y_hat = y_hat.view(y_hat.size(0)*y_hat.size(1), -1)\n",
    "        y = y.view(-1)\n",
    "        loss = loss_func(y_hat, y.long()).sum()\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_l_sum += loss.item() * y.size(0)\n",
    "        train_acc_sum += (y_hat.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.size(0)\n",
    "\n",
    "        if epoch % 500  == 0:\n",
    "            print('epoch %d, perplexity %.4f, train acc %.3f'\n",
    "                  % (epoch, math.exp(train_l_sum / n), train_acc_sum*1. / n))\n",
    "\n",
    "            enc_x, enc_y, y = get_string_batch(1, 8)\n",
    "            state = init_rnn_state(1, num_hiddens)\n",
    "            y_hat = predict_rnn_pytorch(enc_x, model, state)\n",
    "            print('predict', ''.join([chr(i+64) for i in y[0]]), y_hat)\n",
    "\n",
    "    pred_txt = []\n",
    "    for X in test_set:\n",
    "        enc_x = get_test_batch(X)\n",
    "        state = init_rnn_state(1, num_hiddens)\n",
    "        y_hat = predict_rnn_pytorch(enc_x, model, state)\n",
    "        pred_txt += [y_hat]\n",
    "    g = open('output/predict.txt', 'w')\n",
    "    g.write('\\n'.join(pred_txt))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df89bec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def zip_fun():\n",
    "    path=os.getcwd()\n",
    "    newpath=path+\"/output/\"\n",
    "    os.chdir(newpath)\n",
    "    os.system('zip prediction.zip predict.txt')\n",
    "    os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97491b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500, perplexity 26.2720, train acc 0.061\n",
      "predict VYQENWSS VIQLEJZJ\n",
      "epoch 1000, perplexity 25.8116, train acc 0.062\n",
      "predict IZUESEES IQGIKIJZ\n",
      "epoch 1500, perplexity 24.6952, train acc 0.121\n",
      "predict QKUVCGAH AVVHAEJU\n",
      "epoch 2000, perplexity 22.7316, train acc 0.170\n",
      "predict UJJUWSTD JJTSWFCJ\n",
      "epoch 2500, perplexity 21.1562, train acc 0.168\n",
      "predict UVTHDFUI VDDFUJJT\n",
      "epoch 3000, perplexity 19.3947, train acc 0.205\n",
      "predict LEEILEZF ELQFLEEJ\n",
      "epoch 3500, perplexity 17.0676, train acc 0.268\n",
      "predict ESYTMHBP BJTTMMSB\n",
      "epoch 4000, perplexity 13.1603, train acc 0.359\n",
      "predict TZDGTHWV ZZDDVVTT\n",
      "epoch 4500, perplexity 10.0927, train acc 0.422\n",
      "predict JIYPDTVK JJKPDJJK\n",
      "epoch 5000, perplexity 7.3448, train acc 0.564\n",
      "predict DLMZYSMK LDZYIMKK\n",
      "epoch 5500, perplexity 5.2547, train acc 0.664\n",
      "predict NZGURWCJ ZGNWRCJJ\n",
      "epoch 6000, perplexity 3.6079, train acc 0.779\n",
      "predict YNXBMAFR YNBXFRHQ\n",
      "epoch 6500, perplexity 2.6996, train acc 0.881\n",
      "predict JESVDJNK JESVDJNK\n",
      "epoch 7000, perplexity 2.0921, train acc 0.951\n",
      "predict ZGHNPYCE ZGHNPYCE\n",
      "epoch 7500, perplexity 1.7715, train acc 0.965\n",
      "predict SNRKSNIP SRKSNIPN\n",
      "epoch 8000, perplexity 1.5261, train acc 0.980\n",
      "predict JHQKKYAK JHQKKYYK\n",
      "epoch 8500, perplexity 1.3965, train acc 0.984\n",
      "predict GTJNNTEJ GTJNNTEJ\n",
      "epoch 9000, perplexity 1.3029, train acc 0.992\n",
      "predict SUVQBNGO SUVQBNGO\n",
      "epoch 9500, perplexity 1.2946, train acc 0.980\n",
      "predict SWWLHRUJ SWWLHRUJ\n",
      "epoch 10000, perplexity 1.2173, train acc 0.992\n",
      "predict OWASUOVG OWASUOVG\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #print('toy_string', toy_string)\n",
    "    test_set = load_file('input/test_X.txt')\n",
    "\n",
    "    train_with_RNN(test_set)\n",
    "\n",
    "    zip_fun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca84e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
