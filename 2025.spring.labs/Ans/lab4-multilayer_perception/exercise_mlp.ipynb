{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from feedforward_np_version import Model_NP\n",
    "from feedforward_pytorch_version import Model_Pytorch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import gzip\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def display_mnist():\n",
    "    data_train = MNISTDataset('./input/train', train=True)\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(data_train[i][0], cmap='gray', interpolation='none')\n",
    "        plt.title(\"Ground Truth: {}\".format(data_train[i][1]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTDataset():\n",
    "    def __init__(self, data_path, train=True, transform=None):\n",
    "        X, y = self.load_data(data_path, train)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.y is None:\n",
    "            return img\n",
    "        else:\n",
    "            return img, int(self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def load_data(self, data_path, train):\n",
    "        y_train = None\n",
    "\n",
    "        if train:\n",
    "            with gzip.open(data_path + '-labels.gz', 'rb') as f:\n",
    "                y_train = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "\n",
    "        with gzip.open(data_path + '-images.gz', 'rb') as f:\n",
    "            x_train = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "        return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    train_set = MNISTDataset('./input/train', train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()\n",
    "                             ])\n",
    "                             )\n",
    "    test_set = MNISTDataset('./input/t10k', train=False,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ])\n",
    "                            )\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_Model_NP(train_set, test_set):\n",
    "    def compute_accuracy(log_prob, labels):\n",
    "        predictions = np.argmax(log_prob, axis=1)\n",
    "        truth = np.argmax(labels, axis=1)\n",
    "        return np.sum(predictions == truth)\n",
    "\n",
    "    _, width, height = train_set[0][0].shape\n",
    "    model = Model_NP(width*height, 10)\n",
    "\n",
    "    train_label = np.zeros(shape=[len(train_set), 10])\n",
    "    #test_label = np.zeros(shape=[len(test_set), 10])\n",
    "    train_label[np.arange(len(train_set)), np.array([train_set[i][1] for i in np.arange(len(train_set))])] = 1.\n",
    "    #test_label[np.arange(len(test_set)), np.array([test_set[i][1] for i in np.arange(len(test_set))])] = 1.\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "\n",
    "        X = np.concatenate([train_set[i][0] for i in np.arange(len(train_set))], axis = 0)\n",
    "        y = train_label\n",
    "        pred_y = model.forward(X)\n",
    "        model.backward(y)\n",
    "        model.update()\n",
    "        loss = model.compute_loss(pred_y, y)\n",
    "        accuracy = compute_accuracy(pred_y, y)\n",
    "\n",
    "        train_l_sum += loss\n",
    "        train_acc_sum += accuracy\n",
    "        n += y.shape[0]\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch %d, loss %.4f, train acc %.3f'\n",
    "                  % (epoch, train_l_sum / n, train_acc_sum / n)); # exit()\n",
    "\n",
    "    X = np.stack([test_set[i][0] for i in np.arange(len(test_set))], axis = 0)\n",
    "    h2_log = model.forward(X)\n",
    "    predictions = np.argmax(h2_log, axis=1)\n",
    "    pred_txt = [str(w) for w in predictions]\n",
    "    g = open('output/predict.txt', 'w')\n",
    "    g.write('\\n'.join(pred_txt))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_Model_Pytorch(train_set, test_set):\n",
    "    depth, width, height = train_set[0][0].shape\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    #test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)\n",
    "\n",
    "    model = Model_Pytorch(width*height, 10)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_l_sum, train_acc_sum, n = 0., 0., 0\n",
    "        for X, y in train_dataloader:\n",
    "            #print(y)\n",
    "            y_hat = model(X).squeeze(1)\n",
    "            loss = loss_func(y_hat, y.long()).sum()\n",
    "\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += loss.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('epoch %d, loss %.4f, train acc %.3f'\n",
    "                % (epoch, train_l_sum / n, train_acc_sum / n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def  zip_fun():\n",
    "    path=os.getcwd()\n",
    "    newpath=path+\"/output/\"\n",
    "    os.chdir(newpath)\n",
    "    os.system('zip prediction.zip predict.txt')\n",
    "    os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:133: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution1 ...\n",
      "epoch 10, loss 14.7991, train acc 0.445\n",
      "epoch 20, loss 10.5243, train acc 0.589\n",
      "epoch 30, loss 6.9644, train acc 0.711\n",
      "epoch 40, loss 5.1713, train acc 0.770\n",
      "epoch 50, loss 2.5399, train acc 0.841\n",
      "epoch 60, loss 1.5560, train acc 0.878\n",
      "epoch 70, loss 1.2534, train acc 0.886\n",
      "epoch 80, loss 1.0853, train acc 0.888\n",
      "epoch 90, loss 0.9561, train acc 0.888\n",
      "epoch 100, loss 0.8636, train acc 0.888\n",
      "model with pytorch ...\n",
      "epoch 5, loss 0.0243, train acc 0.921\n",
      "epoch 10, loss 0.0239, train acc 0.938\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_set, test_set = load_mnist()\n",
    "\n",
    "    #display_mnist()\n",
    "\n",
    "    train_with_Model_NP(train_set, test_set)\n",
    "\n",
    "    train_with_Model_Pytorch(train_set, test_set)\n",
    "\n",
    "    zip_fun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
